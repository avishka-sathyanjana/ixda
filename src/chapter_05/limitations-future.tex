\section{Limitations and Future Work}
\label{sec:limitations-future-work}

This research focused on five basic emotions (Happy, Angry, Sad, Boredom, and Calm) which helped build the core of the system, but these do not fully represent the entire arousal-valence plane. Including a wider range of emotional categories like fear, surprise, or mixed emotions would make the system more complete and useful in real-life applications. Also, the use of only facial and vocal signals may not capture the full complexity of human emotions. Previous studies suggest that physiological signals such as EEG, ECG, and GSR can provide deeper emotional insights and should be explored in future versions. The fusion process in this research was based on a statistical MSE approach, which showed promising results, but more advanced fusion methods like deep learning-based techniques could offer better personalization and flexibility depending on the situation. In terms of emotional baseline estimation, machine learning models can be used to enhance the current KDE-based approach and allow the system to learn and adapt more effectively over time. Lastly, since the experiments were conducted with a small group of participants from similar backgrounds, future work should focus on involving more diverse users in terms of age, language, and culture to ensure the system performs well across different populations.