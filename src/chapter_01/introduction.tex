

\section{Introduction}
\par Imagine a world where your devices not only understand your words but also your emotions, responding with empathy and personalized interactions tailored to your emotional state. This vision drives research in multi-modal emotional state recognition, a field at the intersection of affective computing, human-computer interaction, and artificial intelligence. Affective computing is a multidisciplinary research area where computer science bridges the gap between cognitive science, psychology, and social science. It empowers intelligent systems to recognize, conclude, and interpret human emotions, facilitating better human-machine interaction by responding to humans based on their emotional state \citep{picard2000affective}.


\par The emotional state of individuals varies significantly from person to person (Lim, 2016), making it essential to create customized and personalized models for emotion recognition. This is particularly important for applications like personal assistants, where user satisfaction and engagement are paramount \citep{salama2020deep}. Personalization in emotion identification is essential for building truly adaptable and empathetic systems that can transform industries like healthcare, customer service, education, and entertainment. Research by \cite{gelbrich2021emotional}, \cite{mariacher2021investigating}, and \cite{inkster2018empathy} has expanded this area, showing the potential of emotionally aware AI systems.

\par This study focuses on building a personalized emotion recognition system by first selecting the most effective facial and speech emotion models. These models are then fused to capture emotions more accurately while considering individual differences. An emotional baseline is established for each user, which is later refined through reinforcement learning. The system also explores how incorporating emotional context can improve responses from large language models during user interactions.

\subsection{Motivation}

\par While progress in affective computing has enabled machines to recognize emotions in the moment, a critical challenge remains: capturing the dynamic, personalized nature of emotional experiences. This leads to frustration and dissatisfaction, as these systems provide generic, one-size-fits-all responses that fail to account for user's emotional context \citep{kim2024understanding}.

\par When emotions are triggered, they emerge from a foundational *\textbf{"Baseline"}* or mood, representing our stable emotional state. Emotional changes can be understood as shifts or escalations from this baseline \citep{davidson1998affective}. By disregarding the baseline, these systems miss an essential element of emotional understanding, leading to responses that may feel disconnected or inadequate. For instance, in urgent situations, long responses can increase frustration, while in joyful moments, generic responses can reduce engagement.


\subsection{Research Gap}

\par Most current systems overlook the significance of longitudinal analysis and fail to capture individual baseline behavior. Neglecting these unique emotional baselines can compromise accuracy of emotion identification, as readings may not align with an individual's natural emotional biases. This research aims to bridge this gap by developing a framework that collects long-term multimodal data to understand each person's emotional baseline, enabling adaptive shifts in these baselines over time. By considering individuals' baseline behavior alongside a multimodal approach combining facial expressions and interaction patterns, the proposed system strives to achieve precise, personalized, and context-aware emotion recognition.

\subsection{Significance of the Research}

\par This research addresses a critical gap: the lack of emotional awareness and personalized responses in current AI systems. By developing systems that accurately recognize users' emotional states through multimodal data in a more personalized way using fine-tuned weights according to user emotions.

\par Also, it captures the baseline of users' emotion in context, and system continuously monitors for deviations, identifying subtle emotional shifts that represent changes from user's typical emotional state. Through an iterative process, the system will adjust the baseline of the user from time to time.

\par This personalized emotional insight is crucial in domains where ongoing and accurate understanding of user emotions is essential, such as mental health support, customer service, and adaptive learning. By focusing on both baseline and changes in emotional states, our approach paves the way for interactions that are genuinely responsive, supportive, and adaptive to users' evolving emotional needs.